{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18b2294f-fb8e-48b5-9013-216c1ba2c04f",
   "metadata": {},
   "source": [
    "---\n",
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21621115-ec57-4366-845b-506436905ca4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook aicup_bert_lstm.ipynb to script\n",
      "[NbConvertApp] Writing 14892 bytes to aicup_bert_lstm.py\n"
     ]
    }
   ],
   "source": [
    "# !jupyter nbconvert --output-dir=\"./final\" --to script aicup_bert_lstm.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1136b115-c807-4fdd-97cb-92592f70ac1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import torch, pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from transformers import set_seed\n",
    "set_seed(123)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32a5ace-573a-41a5-91ba-fe3ece10fd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>q'</th>\n",
       "      <th>r'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>\"True .\"</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>\"True .\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>\"True .\"</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"can go both ways . We all doubt . It is what ...</td>\n",
       "      <td>\"True\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>\"True .\"</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"It can go both ways . We all doubt . It is wh...</td>\n",
       "      <td>\"True\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>\"once again , you seem to support the killing ...</td>\n",
       "      <td>\"based on the idea that people are dispensible...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"seem to support the killing of certain people\"</td>\n",
       "      <td>\"based on the idea that people are dispensible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>\"once again , you seem to support the killing ...</td>\n",
       "      <td>\"based on the idea that people are dispensible...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"you seem to support the killing of certain pe...</td>\n",
       "      <td>\"based on the idea that people are dispensible\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38341</th>\n",
       "      <td>10001</td>\n",
       "      <td>\"good thing this argument has never been done ...</td>\n",
       "      <td>\"And teen sex does n't , by the very nature of...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>\"You are much better off making theft legal an...</td>\n",
       "      <td>\"And teen sex does n't , by the very nature of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38342</th>\n",
       "      <td>10002</td>\n",
       "      <td>\"I know one thing , anything that happens , po...</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>\"I know one thing , anything that happens , po...</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38343</th>\n",
       "      <td>10002</td>\n",
       "      <td>\"I know one thing , anything that happens , po...</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>\"FBI Arrests Three Men in Terror Plot that Tar...</td>\n",
       "      <td>\"Was n't sinjin crowing about his plans to tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38344</th>\n",
       "      <td>10003</td>\n",
       "      <td>\"I enjoy Botany more than most things and I ha...</td>\n",
       "      <td>\"Hi Smallax , welcome to the forum . I did a s...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"I enjoy Botany more than most things and I ha...</td>\n",
       "      <td>\"Hi Smallax , welcome to the forum . I did a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38345</th>\n",
       "      <td>10003</td>\n",
       "      <td>\"I enjoy Botany more than most things and I ha...</td>\n",
       "      <td>\"Hi Smallax , welcome to the forum . I did a s...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>\"bringing in outside sun light through fiber o...</td>\n",
       "      <td>\"might give you an idea about costs and concep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38346 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                                  q  \\\n",
       "0          8  \"It can go both ways . We all doubt . It is wh...   \n",
       "1          8  \"It can go both ways . We all doubt . It is wh...   \n",
       "2          8  \"It can go both ways . We all doubt . It is wh...   \n",
       "3          9  \"once again , you seem to support the killing ...   \n",
       "4          9  \"once again , you seem to support the killing ...   \n",
       "...      ...                                                ...   \n",
       "38341  10001  \"good thing this argument has never been done ...   \n",
       "38342  10002  \"I know one thing , anything that happens , po...   \n",
       "38343  10002  \"I know one thing , anything that happens , po...   \n",
       "38344  10003  \"I enjoy Botany more than most things and I ha...   \n",
       "38345  10003  \"I enjoy Botany more than most things and I ha...   \n",
       "\n",
       "                                                       r         s  \\\n",
       "0                                               \"True .\"     AGREE   \n",
       "1                                               \"True .\"     AGREE   \n",
       "2                                               \"True .\"     AGREE   \n",
       "3      \"based on the idea that people are dispensible...     AGREE   \n",
       "4      \"based on the idea that people are dispensible...     AGREE   \n",
       "...                                                  ...       ...   \n",
       "38341  \"And teen sex does n't , by the very nature of...  DISAGREE   \n",
       "38342  \"Was n't sinjin crowing about his plans to tak...  DISAGREE   \n",
       "38343  \"Was n't sinjin crowing about his plans to tak...  DISAGREE   \n",
       "38344  \"Hi Smallax , welcome to the forum . I did a s...     AGREE   \n",
       "38345  \"Hi Smallax , welcome to the forum . I did a s...     AGREE   \n",
       "\n",
       "                                                      q'  \\\n",
       "0      \"It can go both ways . We all doubt . It is wh...   \n",
       "1      \"can go both ways . We all doubt . It is what ...   \n",
       "2      \"It can go both ways . We all doubt . It is wh...   \n",
       "3        \"seem to support the killing of certain people\"   \n",
       "4      \"you seem to support the killing of certain pe...   \n",
       "...                                                  ...   \n",
       "38341  \"You are much better off making theft legal an...   \n",
       "38342  \"I know one thing , anything that happens , po...   \n",
       "38343  \"FBI Arrests Three Men in Terror Plot that Tar...   \n",
       "38344  \"I enjoy Botany more than most things and I ha...   \n",
       "38345  \"bringing in outside sun light through fiber o...   \n",
       "\n",
       "                                                      r'  \n",
       "0                                               \"True .\"  \n",
       "1                                                 \"True\"  \n",
       "2                                                 \"True\"  \n",
       "3      \"based on the idea that people are dispensible...  \n",
       "4        \"based on the idea that people are dispensible\"  \n",
       "...                                                  ...  \n",
       "38341  \"And teen sex does n't , by the very nature of...  \n",
       "38342  \"Was n't sinjin crowing about his plans to tak...  \n",
       "38343  \"Was n't sinjin crowing about his plans to tak...  \n",
       "38344  \"Hi Smallax , welcome to the forum . I did a s...  \n",
       "38345  \"might give you an idea about costs and concep...  \n",
       "\n",
       "[38346 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Batch_answers - train_data (no-blank).csv', encoding=\"ISO-8859-1\")\n",
    "df = df.drop(columns=['Unnamed: 6', 'total no.: 7987'])\n",
    "# df_test = pd.read_csv('Batch_answers - test_data(no_label).csv', encoding=\"ISO-8859-1\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2960e19e-f341-45a4-8bca-440356f4bb85",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e5383e-f7df-418c-a3c2-f09da93048aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>q'</th>\n",
       "      <th>r'</th>\n",
       "      <th>sub_q_true</th>\n",
       "      <th>sub_r_true</th>\n",
       "      <th>sub_both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>It can go both ways . We all doubt . It is wha...</td>\n",
       "      <td>AGREE:True .</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>It can go both ways . We all doubt . It is wha...</td>\n",
       "      <td>True .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>It can go both ways . We all doubt . It is wha...</td>\n",
       "      <td>AGREE:True .</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>can go both ways . We all doubt . It is what y...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>It can go both ways . We all doubt . It is wha...</td>\n",
       "      <td>AGREE:True .</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>It can go both ways . We all doubt . It is wha...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                  q             r      s  \\\n",
       "0   8  It can go both ways . We all doubt . It is wha...  AGREE:True .  AGREE   \n",
       "1   8  It can go both ways . We all doubt . It is wha...  AGREE:True .  AGREE   \n",
       "2   8  It can go both ways . We all doubt . It is wha...  AGREE:True .  AGREE   \n",
       "\n",
       "                                                  q'      r'  sub_q_true  \\\n",
       "0  It can go both ways . We all doubt . It is wha...  True .           1   \n",
       "1  can go both ways . We all doubt . It is what y...    True           1   \n",
       "2  It can go both ways . We all doubt . It is wha...    True           1   \n",
       "\n",
       "   sub_r_true  sub_both  \n",
       "0           1         1  \n",
       "1           1         1  \n",
       "2           1         1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['q','r',\"q'\",\"r'\"]] = df[['q','r',\"q'\",\"r'\"]].apply(lambda x: x.str.strip('\\\"'))\n",
    "\n",
    "# # augment 50%\n",
    "df_aug = df.sample(n=int(0.5*len(df)), random_state=1)\n",
    "df = pd.concat([df, df_aug], ignore_index=True)\n",
    "\n",
    "    \n",
    "\n",
    "df['r'] = df['s'] + ':' + df['r']\n",
    "df['sub_q_true'] = [1 if x in y else 0 for x,y in zip(df[\"q'\"],df[\"q\"])]\n",
    "df['sub_r_true'] = [1 if x in y else 0 for x,y in zip(df[\"r'\"],df[\"r\"])]\n",
    "df['sub_both'] = df['sub_q_true']*df['sub_r_true']\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b2bba0a-47c9-4b93-8d84-df2502371713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_860296/2710139891.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['q_start'] = [y.index(x) for x,y in zip(data[\"q'\"],data[\"q\"])]\n",
      "/tmp/ipykernel_860296/2710139891.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['r_start'] = [y.index(x) for x,y in zip(data[\"r'\"],data[\"r\"])]\n",
      "/tmp/ipykernel_860296/2710139891.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['q_end'] = [x+len(y)-1 for x,y in zip(data[\"q_start\"],data[\"q'\"])]\n",
      "/tmp/ipykernel_860296/2710139891.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['r_end'] = [x+len(y)-1 for x,y in zip(data[\"r_start\"],data[\"r'\"])]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>q'</th>\n",
       "      <th>r'</th>\n",
       "      <th>sub_q_true</th>\n",
       "      <th>sub_r_true</th>\n",
       "      <th>sub_both</th>\n",
       "      <th>q_start</th>\n",
       "      <th>r_start</th>\n",
       "      <th>q_end</th>\n",
       "      <th>r_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>It can go both ways . We all doubt . It is wha...</td>\n",
       "      <td>AGREE:True .</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>It can go both ways . We all doubt . It is wha...</td>\n",
       "      <td>True .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>76</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>It can go both ways . We all doubt . It is wha...</td>\n",
       "      <td>AGREE:True .</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>can go both ways . We all doubt . It is what y...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>It can go both ways . We all doubt . It is wha...</td>\n",
       "      <td>AGREE:True .</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>It can go both ways . We all doubt . It is wha...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>once again , you seem to support the killing o...</td>\n",
       "      <td>AGREE:based on the idea that people are dispen...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>seem to support the killing of certain people</td>\n",
       "      <td>based on the idea that people are dispensible ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>61</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>once again , you seem to support the killing o...</td>\n",
       "      <td>AGREE:based on the idea that people are dispen...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>you seem to support the killing of certain peo...</td>\n",
       "      <td>based on the idea that people are dispensible</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>81</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57513</th>\n",
       "      <td>996</td>\n",
       "      <td>If you want an answer to that , I suggest you ...</td>\n",
       "      <td>DISAGREE:What are you afraid of , Trebor ? ? T...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>If you want an answer to that , I suggest you ...</td>\n",
       "      <td>What are you afraid of , Trebor ? ? The whole ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>59</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57514</th>\n",
       "      <td>378</td>\n",
       "      <td>Now that 's a bald-faced lie</td>\n",
       "      <td>DISAGREE:No - it 's not . Your stand on rape v...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>Now that 's a bald-faced lie</td>\n",
       "      <td>No - it 's not . Your stand on rape victims pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57515</th>\n",
       "      <td>4002</td>\n",
       "      <td>You are making some false assumptions . Howeve...</td>\n",
       "      <td>DISAGREE:Yep , he dodged it again . Care to ex...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>You are making some false assumptions .</td>\n",
       "      <td>Yep , he dodged it again .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57517</th>\n",
       "      <td>5445</td>\n",
       "      <td>everything . it states that you can not discri...</td>\n",
       "      <td>DISAGREE:By that logic being black or of some ...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>thats discrimination</td>\n",
       "      <td>That 's not correct .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>79</td>\n",
       "      <td>197</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57518</th>\n",
       "      <td>8210</td>\n",
       "      <td>Let me get this straight . We ca n't force a w...</td>\n",
       "      <td>AGREE:Yes because it is `` officially `` a lif...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>we can force the father to pay for the child '...</td>\n",
       "      <td>Yes because it is `` officially `` a life .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>6</td>\n",
       "      <td>204</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44707 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                                  q  \\\n",
       "0         8  It can go both ways . We all doubt . It is wha...   \n",
       "1         8  It can go both ways . We all doubt . It is wha...   \n",
       "2         8  It can go both ways . We all doubt . It is wha...   \n",
       "3         9  once again , you seem to support the killing o...   \n",
       "4         9  once again , you seem to support the killing o...   \n",
       "...     ...                                                ...   \n",
       "57513   996  If you want an answer to that , I suggest you ...   \n",
       "57514   378                       Now that 's a bald-faced lie   \n",
       "57515  4002  You are making some false assumptions . Howeve...   \n",
       "57517  5445  everything . it states that you can not discri...   \n",
       "57518  8210  Let me get this straight . We ca n't force a w...   \n",
       "\n",
       "                                                       r         s  \\\n",
       "0                                           AGREE:True .     AGREE   \n",
       "1                                           AGREE:True .     AGREE   \n",
       "2                                           AGREE:True .     AGREE   \n",
       "3      AGREE:based on the idea that people are dispen...     AGREE   \n",
       "4      AGREE:based on the idea that people are dispen...     AGREE   \n",
       "...                                                  ...       ...   \n",
       "57513  DISAGREE:What are you afraid of , Trebor ? ? T...  DISAGREE   \n",
       "57514  DISAGREE:No - it 's not . Your stand on rape v...  DISAGREE   \n",
       "57515  DISAGREE:Yep , he dodged it again . Care to ex...  DISAGREE   \n",
       "57517  DISAGREE:By that logic being black or of some ...  DISAGREE   \n",
       "57518  AGREE:Yes because it is `` officially `` a lif...     AGREE   \n",
       "\n",
       "                                                      q'  \\\n",
       "0      It can go both ways . We all doubt . It is wha...   \n",
       "1      can go both ways . We all doubt . It is what y...   \n",
       "2      It can go both ways . We all doubt . It is wha...   \n",
       "3          seem to support the killing of certain people   \n",
       "4      you seem to support the killing of certain peo...   \n",
       "...                                                  ...   \n",
       "57513  If you want an answer to that , I suggest you ...   \n",
       "57514                       Now that 's a bald-faced lie   \n",
       "57515            You are making some false assumptions .   \n",
       "57517                               thats discrimination   \n",
       "57518  we can force the father to pay for the child '...   \n",
       "\n",
       "                                                      r'  sub_q_true  \\\n",
       "0                                                 True .           1   \n",
       "1                                                   True           1   \n",
       "2                                                   True           1   \n",
       "3      based on the idea that people are dispensible ...           1   \n",
       "4          based on the idea that people are dispensible           1   \n",
       "...                                                  ...         ...   \n",
       "57513  What are you afraid of , Trebor ? ? The whole ...           1   \n",
       "57514  No - it 's not . Your stand on rape victims pr...           1   \n",
       "57515                         Yep , he dodged it again .           1   \n",
       "57517                              That 's not correct .           1   \n",
       "57518        Yes because it is `` officially `` a life .           1   \n",
       "\n",
       "       sub_r_true  sub_both  q_start  r_start  q_end  r_end  \n",
       "0               1         1        0        6     76     11  \n",
       "1               1         1        3        6     74      9  \n",
       "2               1         1        0        6     76      9  \n",
       "3               1         1       17        6     61     98  \n",
       "4               1         1       13        6     81     50  \n",
       "...           ...       ...      ...      ...    ...    ...  \n",
       "57513           1         1        0        9     59    111  \n",
       "57514           1         1        0        9     27     61  \n",
       "57515           1         1        0        9     38     34  \n",
       "57517           1         1      178       79    197     99  \n",
       "57518           1         1      102        6    204     48  \n",
       "\n",
       "[44707 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.loc[df['sub_both'] == 1]\n",
    "data['q_start'] = [y.index(x) for x,y in zip(data[\"q'\"],data[\"q\"])]\n",
    "data['r_start'] = [y.index(x) for x,y in zip(data[\"r'\"],data[\"r\"])]\n",
    "data['q_end'] = [x+len(y)-1 for x,y in zip(data[\"q_start\"],data[\"q'\"])]\n",
    "data['r_end'] = [x+len(y)-1 for x,y in zip(data[\"r_start\"],data[\"r'\"])]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38c3eac0-3291-4255-9c15-335647aba3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, valid = train_test_split(data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6363a5a4-5cf0-4d30-b583-35ccf7415b1f",
   "metadata": {},
   "source": [
    "---\n",
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5a89455-222e-4d3a-9251-3079accde541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6afa1dce-5cba-4aa2-ad24-3edaf563979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_q = train['q'].tolist()\n",
    "valid_data_q = valid['q'].tolist()\n",
    "\n",
    "train_data_r = train['r'].tolist()\n",
    "valid_data_r = valid['r'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46af2954-7ba3-4530-a8dc-c5e9ce3cb646",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_data_q, train_data_r, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(valid_data_q, valid_data_r, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "605740b3-aa74-4a03-b814-87b4667c8787",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_answer = train[['q_start', 'r_start',\t'q_end', 'r_end']].to_dict('records')\n",
    "valid_answer = valid[['q_start', 'r_start',\t'q_end', 'r_end']].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47035fea-44f4-49d7-8860-1e07d64bf0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    q_start, r_start, q_end, r_end = [],[],[],[]\n",
    "\n",
    "    for i in range(len(answers)):\n",
    "        # print(i)\n",
    "        q_start.append(encodings.char_to_token(i, answers[i]['q_start'], 0))\n",
    "        r_start.append(encodings.char_to_token(i, answers[i]['r_start'], 1))\n",
    "        q_end.append(encodings.char_to_token(i, answers[i]['q_end'], 0))\n",
    "        r_end.append(encodings.char_to_token(i, answers[i]['r_end'], 1))\n",
    "\n",
    "        if q_start[-1] is None:\n",
    "            q_start[-1] = 0\n",
    "            q_end[-1] = 0\n",
    "            # continue\n",
    "\n",
    "        if r_start[-1] is None:\n",
    "            r_start[-1] = 0\n",
    "            r_end[-1] = 0\n",
    "            # continue\n",
    "\n",
    "        shift = 1\n",
    "        while q_end[-1] is None:\n",
    "            q_end[-1] = encodings.char_to_token(i, answers[i]['q_end'] - shift)\n",
    "            shift += 1\n",
    "        shift = 1\n",
    "        while r_end[-1] is None:\n",
    "            r_end[-1] = encodings.char_to_token(i, answers[i]['r_end'] - shift)\n",
    "            shift += 1\n",
    "    encodings.update({'q_start':q_start, 'r_start':r_start,\t'q_end':q_end, 'r_end':r_end})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a1673ee-73d4-4c1f-b096-05566c00de67",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert char_based_id to token_based_id\n",
    "# Find the corresponding token id after input being tokenized\n",
    "add_token_positions(train_encodings, train_answer)\n",
    "add_token_positions(val_encodings, valid_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82e05d2e-cec1-4e1b-bbdb-8b08268e6050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'q_start', 'r_start', 'q_end', 'r_end'])\n",
      "3\n",
      "54\n",
      "24\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "print(train_encodings.keys())\n",
    "print(train_encodings['q_start'][0])\n",
    "print(train_encodings['r_start'][0])\n",
    "print(train_encodings['q_end'][0])\n",
    "print(train_encodings['r_end'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148d7899-18b7-4570-b761-3215ca6a2699",
   "metadata": {},
   "source": [
    "---\n",
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c9866f2-2e8c-49a4-a271-ef1b31e29410",
   "metadata": {},
   "outputs": [],
   "source": [
    "class qrDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98f22025-23c0-487c-b116-9ce994dbb886",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = qrDataset(train_encodings)\n",
    "val_dataset = qrDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3be944-d0e1-498e-8af3-1937ae0e6476",
   "metadata": {},
   "source": [
    "---\n",
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a64712ed-cfab-4ac6-9925-d06f2f348106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "class myModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(myModel, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.lstm = nn.LSTM(768, 256, batch_first=True, bidirectional=True, num_layers=2)\n",
    "        self.fc = nn.Linear(256*2, 4)\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, return_dict=True)\n",
    "        logits = output[0]\n",
    "        logits, _ = self.lstm(logits)\n",
    "        # print(logits)\n",
    "        # print(logits.shape)\n",
    "        out = self.fc(logits)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb2d7b51-127c-4d3f-b34b-d2b3d35efa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/root/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "epochs = 2\n",
    "loss_fct = CrossEntropyLoss()\n",
    "total_steps = len(train_loader) * epochs\n",
    "model = myModel().to(device)\n",
    "optim = AdamW(model.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96e19697-26ec-422f-9b87-1a945dae178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(valid_loader):\n",
    "    q_acc, r_acc = [], []\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(valid_loader, leave=True)\n",
    "        for batch_id, batch in enumerate(loop):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            q_start = batch['q_start'].to(device)\n",
    "            r_start = batch['r_start'].to(device)\n",
    "            q_end = batch['q_end'].to(device)\n",
    "            r_end = batch['r_end'].to(device)\n",
    "\n",
    "            # model output\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "            # q_start_logits, r_start_logits, q_end_logits, r_end_logits = torch.split(outputs, 1, 1)\n",
    "            q_start_logits, r_start_logits, q_end_logits, r_end_logits = torch.split(outputs, 1, 2)\n",
    "            \n",
    "            \n",
    "            q_start_pred = torch.argmax(q_start_logits, dim=1)\n",
    "            r_start_pred = torch.argmax(r_start_logits, dim=1)\n",
    "            q_end_pred = torch.argmax(q_end_logits, dim=1)\n",
    "            r_end_pred = torch.argmax(r_end_logits, dim=1)\n",
    "\n",
    "            q_start_logits = q_start_logits.squeeze(-1).contiguous()\n",
    "            r_start_logits = r_start_logits.squeeze(-1).contiguous()\n",
    "            q_end_logits = q_end_logits.squeeze(-1).contiguous()\n",
    "            r_end_logits = r_end_logits.squeeze(-1).contiguous()\n",
    "\n",
    "            q_start_loss = loss_fct(q_start_logits, q_start)\n",
    "            r_start_loss = loss_fct(r_start_logits, r_start)\n",
    "            q_end_loss = loss_fct(q_end_logits, q_end)\n",
    "            r_end_loss = loss_fct(r_end_logits, r_end)\n",
    "\n",
    "            loss = q_start_loss + r_start_loss + q_end_loss + r_end_loss\n",
    "            \n",
    "            q_start = q_start.reshape([q_start.size(dim=0),1])\n",
    "            r_start = r_start.reshape([r_start.size(dim=0),1])\n",
    "            q_end = q_end.reshape([q_end.size(dim=0),1])\n",
    "            r_end = r_end.reshape([r_end.size(dim=0),1])\n",
    "            \n",
    "            q_start_score = ((q_start_pred == q_start).sum()/len(q_start_pred)).item()\n",
    "            r_start_score = ((r_start_pred == r_start).sum()/len(r_start_pred)).item() \n",
    "            q_end_score = ((q_end_pred == q_end).sum()/len(q_end_pred)).item() \n",
    "            r_end_score = ((r_end_pred == r_end).sum()/len(r_end_pred)).item() \n",
    "            \n",
    "            q_acc.append(q_start_score)\n",
    "            q_acc.append(q_end_score)\n",
    "            r_acc.append(r_start_score)\n",
    "            r_acc.append(r_end_score)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if batch_id % 30 == 0 and batch_id != 0:\n",
    "                print('Validation Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "                    batch_id + 1, batch_id, running_loss / 30))\n",
    "                running_loss = 0.0\n",
    "        q_acc = sum(q_acc)/len(q_acc)\n",
    "        r_acc = sum(r_acc)/len(r_acc)\n",
    "\n",
    "        print(\"evaluate loss: \", loss)\n",
    "        print(\"q-acc: \", q_acc)\n",
    "        print(\"r-acc: \", r_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "225c6194-34ad-4245-a89b-e6dd9a9571d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1% 51/5030 [00:20<32:42,  2.54it/s, loss=17.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 50 Loss 21.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   2% 101/5030 [00:39<32:38,  2.52it/s, loss=10.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101 Batch 100 Loss 13.2888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   3% 151/5030 [00:59<32:29,  2.50it/s, loss=9.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151 Batch 150 Loss 10.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   4% 201/5030 [01:19<32:14,  2.50it/s, loss=11.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201 Batch 200 Loss 9.4608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   5% 251/5030 [01:39<31:58,  2.49it/s, loss=6.49]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251 Batch 250 Loss 8.6182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   6% 301/5030 [01:59<31:39,  2.49it/s, loss=11]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301 Batch 300 Loss 8.1936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   7% 351/5030 [02:20<31:25,  2.48it/s, loss=7.09]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351 Batch 350 Loss 8.4997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   8% 401/5030 [02:40<31:04,  2.48it/s, loss=7.12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401 Batch 400 Loss 8.0528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   9% 451/5030 [03:00<30:43,  2.48it/s, loss=8.5] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451 Batch 450 Loss 8.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  10% 501/5030 [03:20<30:27,  2.48it/s, loss=7.75]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501 Batch 500 Loss 7.6395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  11% 551/5030 [03:40<30:06,  2.48it/s, loss=8.49]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 551 Batch 550 Loss 7.6743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  12% 601/5030 [04:00<29:46,  2.48it/s, loss=10.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601 Batch 600 Loss 7.4856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  13% 651/5030 [04:20<29:26,  2.48it/s, loss=6.23]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 651 Batch 650 Loss 7.5648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  14% 701/5030 [04:41<29:08,  2.48it/s, loss=8.08]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 701 Batch 700 Loss 7.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  15% 751/5030 [05:01<28:47,  2.48it/s, loss=3.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 751 Batch 750 Loss 7.5555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  16% 801/5030 [05:21<28:24,  2.48it/s, loss=5.64]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 801 Batch 800 Loss 7.5851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  17% 851/5030 [05:41<28:03,  2.48it/s, loss=5.24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 851 Batch 850 Loss 7.4479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  18% 901/5030 [06:01<27:47,  2.48it/s, loss=6.91]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901 Batch 900 Loss 7.4912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  19% 951/5030 [06:22<27:25,  2.48it/s, loss=5.27]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 951 Batch 950 Loss 7.4550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  20% 1001/5030 [06:42<27:04,  2.48it/s, loss=9.87]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1001 Batch 1000 Loss 7.6206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  21% 1051/5030 [07:02<26:45,  2.48it/s, loss=8.22]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1051 Batch 1050 Loss 7.2762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  22% 1101/5030 [07:22<26:23,  2.48it/s, loss=6.09]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1101 Batch 1100 Loss 7.4452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  23% 1151/5030 [07:42<26:02,  2.48it/s, loss=7.01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1151 Batch 1150 Loss 7.2564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  24% 1201/5030 [08:02<25:45,  2.48it/s, loss=8.76]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1201 Batch 1200 Loss 7.3205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  25% 1251/5030 [08:22<25:24,  2.48it/s, loss=7.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1251 Batch 1250 Loss 7.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  26% 1301/5030 [08:43<25:07,  2.47it/s, loss=6.83]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1301 Batch 1300 Loss 7.0879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  27% 1351/5030 [09:03<24:42,  2.48it/s, loss=7.83]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1351 Batch 1350 Loss 7.2828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  28% 1401/5030 [09:23<24:24,  2.48it/s, loss=6.04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1401 Batch 1400 Loss 6.9284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  29% 1451/5030 [09:43<24:03,  2.48it/s, loss=5.12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1451 Batch 1450 Loss 7.5758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  30% 1501/5030 [10:03<23:41,  2.48it/s, loss=6.93]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1501 Batch 1500 Loss 7.6328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  31% 1551/5030 [10:23<23:22,  2.48it/s, loss=9.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1551 Batch 1550 Loss 6.7584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  32% 1601/5030 [10:44<23:03,  2.48it/s, loss=6.23]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1601 Batch 1600 Loss 7.4103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  33% 1651/5030 [11:04<22:43,  2.48it/s, loss=6.78]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1651 Batch 1650 Loss 7.6692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  34% 1701/5030 [11:24<22:22,  2.48it/s, loss=7]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1701 Batch 1700 Loss 7.5459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  35% 1751/5030 [11:44<22:01,  2.48it/s, loss=6.91]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1751 Batch 1750 Loss 7.4474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  36% 1801/5030 [12:04<21:42,  2.48it/s, loss=6.04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1801 Batch 1800 Loss 7.3444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  37% 1851/5030 [12:24<21:21,  2.48it/s, loss=5.6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1851 Batch 1850 Loss 6.9822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  38% 1901/5030 [12:45<21:02,  2.48it/s, loss=8.42]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1901 Batch 1900 Loss 7.4584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  39% 1951/5030 [13:05<20:40,  2.48it/s, loss=9.21]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1951 Batch 1950 Loss 7.0557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  40% 2001/5030 [13:25<20:19,  2.48it/s, loss=6.89]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2001 Batch 2000 Loss 6.9085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  41% 2051/5030 [13:45<20:00,  2.48it/s, loss=6.89]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2051 Batch 2050 Loss 7.1698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  42% 2101/5030 [14:05<19:43,  2.48it/s, loss=7.43]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2101 Batch 2100 Loss 7.3147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  43% 2151/5030 [14:25<19:21,  2.48it/s, loss=7.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2151 Batch 2150 Loss 7.0788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  44% 2201/5030 [14:46<19:00,  2.48it/s, loss=5.89]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2201 Batch 2200 Loss 6.9944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  45% 2251/5030 [15:06<18:41,  2.48it/s, loss=6.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2251 Batch 2250 Loss 7.4948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  46% 2301/5030 [15:26<18:20,  2.48it/s, loss=6.31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2301 Batch 2300 Loss 7.5865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  47% 2351/5030 [15:46<17:59,  2.48it/s, loss=7.43]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2351 Batch 2350 Loss 7.3789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  48% 2401/5030 [16:06<17:42,  2.48it/s, loss=6.38]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2401 Batch 2400 Loss 7.4115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  49% 2451/5030 [16:26<17:20,  2.48it/s, loss=10.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2451 Batch 2450 Loss 7.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50% 2501/5030 [16:46<16:59,  2.48it/s, loss=8.07]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2501 Batch 2500 Loss 7.2270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  51% 2551/5030 [17:07<16:37,  2.49it/s, loss=5.57]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2551 Batch 2550 Loss 7.2889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  52% 2601/5030 [17:27<16:19,  2.48it/s, loss=7.74]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2601 Batch 2600 Loss 7.0787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  53% 2651/5030 [17:47<15:59,  2.48it/s, loss=8.58]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2651 Batch 2650 Loss 7.1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  54% 2701/5030 [18:07<15:40,  2.48it/s, loss=9.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2701 Batch 2700 Loss 7.2242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  55% 2751/5030 [18:27<15:19,  2.48it/s, loss=7.16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2751 Batch 2750 Loss 7.2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  56% 2801/5030 [18:47<15:00,  2.48it/s, loss=9.81]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2801 Batch 2800 Loss 7.6439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  57% 2851/5030 [19:08<14:38,  2.48it/s, loss=5.85]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2851 Batch 2850 Loss 7.0645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  58% 2901/5030 [19:28<14:17,  2.48it/s, loss=9.1] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2901 Batch 2900 Loss 7.2761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  59% 2951/5030 [19:48<13:58,  2.48it/s, loss=7.51]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2951 Batch 2950 Loss 6.8905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  60% 3001/5030 [20:08<13:39,  2.48it/s, loss=8.43]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3001 Batch 3000 Loss 7.1234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  61% 3051/5030 [20:28<13:19,  2.48it/s, loss=7.5] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3051 Batch 3050 Loss 6.9222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  62% 3101/5030 [20:49<12:58,  2.48it/s, loss=9.06]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3101 Batch 3100 Loss 7.3509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  63% 3151/5030 [21:09<12:38,  2.48it/s, loss=9.96]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3151 Batch 3150 Loss 7.4079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  64% 3201/5030 [21:29<12:16,  2.48it/s, loss=6.96]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3201 Batch 3200 Loss 7.2849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  65% 3251/5030 [21:49<11:57,  2.48it/s, loss=10]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3251 Batch 3250 Loss 7.1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  66% 3301/5030 [22:09<11:36,  2.48it/s, loss=6.48]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3301 Batch 3300 Loss 7.0348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  67% 3351/5030 [22:29<11:16,  2.48it/s, loss=7.35]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3351 Batch 3350 Loss 7.1248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  68% 3401/5030 [22:50<10:56,  2.48it/s, loss=5.31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3401 Batch 3400 Loss 7.1372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  69% 3451/5030 [23:10<10:36,  2.48it/s, loss=5.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3451 Batch 3450 Loss 6.9591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  70% 3501/5030 [23:30<10:16,  2.48it/s, loss=7.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3501 Batch 3500 Loss 7.1687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  71% 3551/5030 [23:50<09:56,  2.48it/s, loss=7]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3551 Batch 3550 Loss 7.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  72% 3601/5030 [24:10<09:35,  2.48it/s, loss=8.87]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3601 Batch 3600 Loss 6.8515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  73% 3651/5030 [24:30<09:16,  2.48it/s, loss=8.51]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3651 Batch 3650 Loss 7.0680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  74% 3701/5030 [24:51<08:56,  2.48it/s, loss=8.76]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3701 Batch 3700 Loss 7.5674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  75% 3751/5030 [25:11<08:35,  2.48it/s, loss=8.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3751 Batch 3750 Loss 7.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  76% 3801/5030 [25:31<08:15,  2.48it/s, loss=10]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3801 Batch 3800 Loss 7.1605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  77% 3851/5030 [25:51<07:55,  2.48it/s, loss=8.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3851 Batch 3850 Loss 6.8114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  78% 3901/5030 [26:11<07:35,  2.48it/s, loss=8.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3901 Batch 3900 Loss 7.0686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  79% 3951/5030 [26:31<07:15,  2.48it/s, loss=7.07]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3951 Batch 3950 Loss 7.1756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  80% 4001/5030 [26:52<06:54,  2.48it/s, loss=6.07]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4001 Batch 4000 Loss 6.7706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  81% 4051/5030 [27:12<06:34,  2.48it/s, loss=8.57]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4051 Batch 4050 Loss 6.8248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  82% 4101/5030 [27:32<06:14,  2.48it/s, loss=6.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4101 Batch 4100 Loss 7.1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  83% 4151/5030 [27:52<05:54,  2.48it/s, loss=4.92]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4151 Batch 4150 Loss 6.8777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  84% 4201/5030 [28:12<05:34,  2.48it/s, loss=5.13]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4201 Batch 4200 Loss 6.8951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  85% 4251/5030 [28:32<05:14,  2.48it/s, loss=6.8] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4251 Batch 4250 Loss 7.1064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  86% 4301/5030 [28:53<04:54,  2.48it/s, loss=10]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4301 Batch 4300 Loss 7.0437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  87% 4351/5030 [29:13<04:33,  2.48it/s, loss=6.1] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4351 Batch 4350 Loss 7.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  87% 4401/5030 [29:33<04:13,  2.48it/s, loss=6.39]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4401 Batch 4400 Loss 6.7145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  88% 4451/5030 [29:53<03:53,  2.48it/s, loss=7.8] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4451 Batch 4450 Loss 6.9808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  89% 4501/5030 [30:13<03:33,  2.48it/s, loss=8.26]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4501 Batch 4500 Loss 7.2743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  90% 4551/5030 [30:33<03:13,  2.48it/s, loss=7.02]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4551 Batch 4550 Loss 6.9554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  91% 4601/5030 [30:54<02:53,  2.48it/s, loss=6.6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4601 Batch 4600 Loss 6.9879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  92% 4651/5030 [31:14<02:32,  2.48it/s, loss=6.45]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4651 Batch 4650 Loss 7.3213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  93% 4701/5030 [31:34<02:12,  2.47it/s, loss=8.9] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4701 Batch 4700 Loss 6.9085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  94% 4751/5030 [31:54<01:52,  2.48it/s, loss=5.16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4751 Batch 4750 Loss 6.8503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  95% 4801/5030 [32:14<01:32,  2.47it/s, loss=7.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4801 Batch 4800 Loss 6.8142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  96% 4851/5030 [32:34<01:12,  2.48it/s, loss=7.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4851 Batch 4850 Loss 6.8655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  97% 4901/5030 [32:55<00:52,  2.48it/s, loss=6.79]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4901 Batch 4900 Loss 6.7579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  98% 4951/5030 [33:15<00:31,  2.48it/s, loss=5.81]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4951 Batch 4950 Loss 7.1485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  99% 5001/5030 [33:35<00:11,  2.48it/s, loss=7.17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5001 Batch 5000 Loss 6.9462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100% 5030/5030 [33:46<00:00,  2.48it/s, loss=6.22]\n",
      "  6% 32/559 [00:04<01:13,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 31 Batch 30 Loss 6.8773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11% 62/559 [00:08<01:09,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 61 Batch 60 Loss 6.6626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16% 92/559 [00:12<01:05,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 91 Batch 90 Loss 6.9285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22% 122/559 [00:17<01:01,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 121 Batch 120 Loss 6.8230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27% 152/559 [00:21<00:57,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 151 Batch 150 Loss 6.8478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33% 182/559 [00:25<00:52,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 181 Batch 180 Loss 7.2115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38% 212/559 [00:29<00:48,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 211 Batch 210 Loss 6.8038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43% 242/559 [00:33<00:44,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 241 Batch 240 Loss 7.1163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% 272/559 [00:38<00:40,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 271 Batch 270 Loss 7.1594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54% 302/559 [00:42<00:36,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 301 Batch 300 Loss 6.9984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59% 332/559 [00:46<00:31,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 331 Batch 330 Loss 6.6570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65% 362/559 [00:50<00:27,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 361 Batch 360 Loss 7.2324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 392/559 [00:55<00:23,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 391 Batch 390 Loss 6.6291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75% 422/559 [00:59<00:19,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 421 Batch 420 Loss 7.0848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81% 452/559 [01:03<00:15,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 451 Batch 450 Loss 6.6655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86% 482/559 [01:07<00:10,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 481 Batch 480 Loss 6.9008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92% 512/559 [01:11<00:06,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 511 Batch 510 Loss 6.9812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97% 542/559 [01:16<00:02,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 541 Batch 540 Loss 6.7501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 559/559 [01:18<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate loss:  tensor(8.7333, device='cuda:0')\n",
      "q-acc:  0.5004472272447269\n",
      "r-acc:  0.4866630462979588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1% 51/5030 [00:20<33:28,  2.48it/s, loss=4.95]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 50 Loss 6.2452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2% 101/5030 [00:40<33:06,  2.48it/s, loss=4.85]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101 Batch 100 Loss 6.1368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3% 151/5030 [01:00<32:47,  2.48it/s, loss=7.29]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151 Batch 150 Loss 6.3135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4% 201/5030 [01:21<32:28,  2.48it/s, loss=5.85]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201 Batch 200 Loss 6.4004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5% 251/5030 [01:41<32:05,  2.48it/s, loss=4.78]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251 Batch 250 Loss 6.2949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6% 301/5030 [02:01<31:47,  2.48it/s, loss=8.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301 Batch 300 Loss 6.4048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7% 351/5030 [02:21<31:27,  2.48it/s, loss=6.65]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351 Batch 350 Loss 6.4885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8% 401/5030 [02:41<31:05,  2.48it/s, loss=8.02]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401 Batch 400 Loss 6.2567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9% 451/5030 [03:01<30:46,  2.48it/s, loss=7.88]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451 Batch 450 Loss 5.9104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10% 501/5030 [03:21<30:25,  2.48it/s, loss=6.38]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501 Batch 500 Loss 5.9590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11% 551/5030 [03:42<30:03,  2.48it/s, loss=3.99]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 551 Batch 550 Loss 6.4416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12% 601/5030 [04:02<29:45,  2.48it/s, loss=5.28]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601 Batch 600 Loss 6.2424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  13% 651/5030 [04:22<29:26,  2.48it/s, loss=5.31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 651 Batch 650 Loss 6.4026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  14% 701/5030 [04:42<29:07,  2.48it/s, loss=6.24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 701 Batch 700 Loss 6.6349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  15% 751/5030 [05:02<28:44,  2.48it/s, loss=5.34]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 751 Batch 750 Loss 6.2507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  16% 801/5030 [05:22<28:26,  2.48it/s, loss=6.25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 801 Batch 800 Loss 6.5686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  17% 851/5030 [05:43<28:05,  2.48it/s, loss=5.85]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 851 Batch 850 Loss 6.5686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  18% 901/5030 [06:03<27:45,  2.48it/s, loss=6.84]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901 Batch 900 Loss 6.7522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  19% 951/5030 [06:23<27:20,  2.49it/s, loss=7.09]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 951 Batch 950 Loss 6.5938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  20% 1001/5030 [06:43<27:03,  2.48it/s, loss=5.47]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1001 Batch 1000 Loss 6.4316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  21% 1051/5030 [07:03<26:46,  2.48it/s, loss=7.26]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1051 Batch 1050 Loss 6.3511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  22% 1101/5030 [07:23<26:22,  2.48it/s, loss=6.41]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1101 Batch 1100 Loss 6.3689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  23% 1151/5030 [07:44<26:04,  2.48it/s, loss=6.87]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1151 Batch 1150 Loss 6.6644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  24% 1201/5030 [08:04<25:42,  2.48it/s, loss=4.96]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1201 Batch 1200 Loss 6.4318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  25% 1251/5030 [08:24<25:24,  2.48it/s, loss=5.9] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1251 Batch 1250 Loss 6.1504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  26% 1301/5030 [08:44<25:03,  2.48it/s, loss=6.24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1301 Batch 1300 Loss 6.2995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  27% 1351/5030 [09:04<24:43,  2.48it/s, loss=7.33]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1351 Batch 1350 Loss 6.2549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  28% 1401/5030 [09:24<24:24,  2.48it/s, loss=8.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1401 Batch 1400 Loss 6.4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  29% 1451/5030 [09:45<24:04,  2.48it/s, loss=4.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1451 Batch 1450 Loss 6.5096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  30% 1501/5030 [10:05<23:43,  2.48it/s, loss=7.36]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1501 Batch 1500 Loss 6.2427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  31% 1551/5030 [10:25<23:21,  2.48it/s, loss=5.38]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1551 Batch 1550 Loss 6.2740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  32% 1601/5030 [10:45<23:01,  2.48it/s, loss=5.56]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1601 Batch 1600 Loss 6.7234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  33% 1651/5030 [11:05<22:43,  2.48it/s, loss=8.02]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1651 Batch 1650 Loss 6.1894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  34% 1701/5030 [11:25<22:21,  2.48it/s, loss=8.3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1701 Batch 1700 Loss 6.3261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  35% 1751/5030 [11:45<22:04,  2.48it/s, loss=6.31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1751 Batch 1750 Loss 6.0283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  36% 1801/5030 [12:06<21:41,  2.48it/s, loss=8.99]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1801 Batch 1800 Loss 6.2684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  37% 1851/5030 [12:26<21:20,  2.48it/s, loss=7.58]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1851 Batch 1850 Loss 6.1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  38% 1901/5030 [12:46<21:00,  2.48it/s, loss=7.77]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1901 Batch 1900 Loss 6.4309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  39% 1951/5030 [13:06<20:40,  2.48it/s, loss=8.03]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1951 Batch 1950 Loss 6.7232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  40% 2001/5030 [13:26<20:19,  2.48it/s, loss=6.18]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2001 Batch 2000 Loss 6.4343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  41% 2051/5030 [13:46<20:02,  2.48it/s, loss=5.66]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2051 Batch 2050 Loss 6.4025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  42% 2101/5030 [14:07<19:41,  2.48it/s, loss=6.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2101 Batch 2100 Loss 6.0362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  43% 2151/5030 [14:27<19:20,  2.48it/s, loss=5.83]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2151 Batch 2150 Loss 6.8338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  44% 2201/5030 [14:47<19:02,  2.48it/s, loss=6.09]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2201 Batch 2200 Loss 6.4357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  45% 2251/5030 [15:07<18:42,  2.48it/s, loss=6]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2251 Batch 2250 Loss 6.2673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  46% 2301/5030 [15:27<18:22,  2.48it/s, loss=5.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2301 Batch 2300 Loss 6.4826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  47% 2351/5030 [15:47<17:59,  2.48it/s, loss=4.12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2351 Batch 2350 Loss 6.2550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  48% 2401/5030 [16:08<17:38,  2.48it/s, loss=4.14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2401 Batch 2400 Loss 6.4030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  49% 2451/5030 [16:28<17:21,  2.48it/s, loss=7.1] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2451 Batch 2450 Loss 6.4799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50% 2501/5030 [16:48<16:58,  2.48it/s, loss=4.99]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2501 Batch 2500 Loss 6.5551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  51% 2551/5030 [17:08<16:40,  2.48it/s, loss=4.88]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2551 Batch 2550 Loss 6.3595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  52% 2601/5030 [17:28<16:19,  2.48it/s, loss=6.38]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2601 Batch 2600 Loss 6.1949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  53% 2651/5030 [17:48<16:00,  2.48it/s, loss=6.31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2651 Batch 2650 Loss 6.6381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  54% 2701/5030 [18:08<15:38,  2.48it/s, loss=4.35]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2701 Batch 2700 Loss 6.1812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  55% 2751/5030 [18:29<15:20,  2.47it/s, loss=4.97]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2751 Batch 2750 Loss 6.6219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  56% 2801/5030 [18:49<14:59,  2.48it/s, loss=9.86]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2801 Batch 2800 Loss 6.1529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  57% 2851/5030 [19:09<14:37,  2.48it/s, loss=7.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2851 Batch 2850 Loss 6.3558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  58% 2901/5030 [19:29<14:18,  2.48it/s, loss=6.5] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2901 Batch 2900 Loss 6.3238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  59% 2951/5030 [19:49<13:57,  2.48it/s, loss=5.31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2951 Batch 2950 Loss 6.5952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  60% 3001/5030 [20:10<13:38,  2.48it/s, loss=5.88]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3001 Batch 3000 Loss 6.4235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  61% 3051/5030 [20:30<13:18,  2.48it/s, loss=7.21]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3051 Batch 3050 Loss 6.1666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  62% 3101/5030 [20:50<12:59,  2.48it/s, loss=6.16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3101 Batch 3100 Loss 6.4755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  63% 3151/5030 [21:10<12:38,  2.48it/s, loss=6.05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3151 Batch 3150 Loss 6.3141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  64% 3201/5030 [21:30<12:17,  2.48it/s, loss=10.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3201 Batch 3200 Loss 6.4692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  65% 3251/5030 [21:50<11:59,  2.47it/s, loss=6.25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3251 Batch 3250 Loss 6.3206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  66% 3301/5030 [22:11<11:37,  2.48it/s, loss=5.75]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3301 Batch 3300 Loss 6.1460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  67% 3351/5030 [22:31<11:16,  2.48it/s, loss=3.27]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3351 Batch 3350 Loss 6.3292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  68% 3401/5030 [22:51<10:56,  2.48it/s, loss=4.45]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3401 Batch 3400 Loss 6.1274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  69% 3451/5030 [23:11<10:35,  2.48it/s, loss=6.75]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3451 Batch 3450 Loss 6.1353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  70% 3501/5030 [23:31<10:17,  2.48it/s, loss=4.63]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3501 Batch 3500 Loss 6.1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  71% 3551/5030 [23:51<09:55,  2.48it/s, loss=6.87]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3551 Batch 3550 Loss 6.5392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  72% 3601/5030 [24:12<09:36,  2.48it/s, loss=7.55]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3601 Batch 3600 Loss 6.3280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  73% 3651/5030 [24:32<09:15,  2.48it/s, loss=8.08]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3651 Batch 3650 Loss 6.0978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  74% 3701/5030 [24:52<08:55,  2.48it/s, loss=6.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3701 Batch 3700 Loss 6.5325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  75% 3751/5030 [25:12<08:35,  2.48it/s, loss=3.99]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3751 Batch 3750 Loss 6.3516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  76% 3801/5030 [25:32<08:15,  2.48it/s, loss=6.08]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3801 Batch 3800 Loss 6.6595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  77% 3851/5030 [25:52<07:55,  2.48it/s, loss=6.16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3851 Batch 3850 Loss 6.5539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  78% 3901/5030 [26:12<07:35,  2.48it/s, loss=7.28]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3901 Batch 3900 Loss 6.4365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  79% 3951/5030 [26:33<07:15,  2.48it/s, loss=5.66]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3951 Batch 3950 Loss 6.1627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  80% 4001/5030 [26:53<06:54,  2.48it/s, loss=8.19]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4001 Batch 4000 Loss 6.3535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  81% 4051/5030 [27:13<06:34,  2.48it/s, loss=6.03]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4051 Batch 4050 Loss 6.4567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  82% 4101/5030 [27:33<06:14,  2.48it/s, loss=4.69]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4101 Batch 4100 Loss 6.5135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  83% 4151/5030 [27:53<05:54,  2.48it/s, loss=6.4] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4151 Batch 4150 Loss 6.1410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  84% 4201/5030 [28:13<05:34,  2.48it/s, loss=7.18]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4201 Batch 4200 Loss 6.6357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  85% 4251/5030 [28:34<05:14,  2.48it/s, loss=5.13]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4251 Batch 4250 Loss 6.4274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  86% 4301/5030 [28:54<04:53,  2.48it/s, loss=7.33]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4301 Batch 4300 Loss 6.3904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  87% 4351/5030 [29:14<04:33,  2.48it/s, loss=6.2] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4351 Batch 4350 Loss 6.1794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  87% 4401/5030 [29:34<04:13,  2.48it/s, loss=6.13]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4401 Batch 4400 Loss 6.5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  88% 4451/5030 [29:54<03:53,  2.48it/s, loss=6.56]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4451 Batch 4450 Loss 6.1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  89% 4501/5030 [30:14<03:33,  2.48it/s, loss=5.86]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4501 Batch 4500 Loss 6.1368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  90% 4551/5030 [30:35<03:13,  2.48it/s, loss=8.38]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4551 Batch 4550 Loss 6.5083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  91% 4601/5030 [30:55<02:53,  2.48it/s, loss=4.03]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4601 Batch 4600 Loss 6.1473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  92% 4651/5030 [31:15<02:32,  2.48it/s, loss=8.34]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4651 Batch 4650 Loss 6.3515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  93% 4701/5030 [31:35<02:12,  2.48it/s, loss=7.46]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4701 Batch 4700 Loss 6.5566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  94% 4751/5030 [31:55<01:52,  2.48it/s, loss=5.89]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4751 Batch 4750 Loss 6.5212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  95% 4801/5030 [32:15<01:32,  2.48it/s, loss=6.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4801 Batch 4800 Loss 6.2283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  96% 4851/5030 [32:36<01:12,  2.48it/s, loss=6.54]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4851 Batch 4850 Loss 6.0970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  97% 4901/5030 [32:56<00:52,  2.48it/s, loss=5.95]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4901 Batch 4900 Loss 6.4836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  98% 4951/5030 [33:16<00:31,  2.48it/s, loss=5.27]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4951 Batch 4950 Loss 6.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  99% 5001/5030 [33:36<00:11,  2.48it/s, loss=6.83]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5001 Batch 5000 Loss 6.4606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100% 5030/5030 [33:48<00:00,  2.48it/s, loss=4.86]\n",
      "  6% 32/559 [00:04<01:13,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 31 Batch 30 Loss 6.5902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11% 62/559 [00:08<01:09,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 61 Batch 60 Loss 6.5076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16% 92/559 [00:12<01:05,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 91 Batch 90 Loss 6.1298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22% 122/559 [00:17<01:01,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 121 Batch 120 Loss 6.6370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27% 152/559 [00:21<00:56,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 151 Batch 150 Loss 6.5198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33% 182/559 [00:25<00:52,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 181 Batch 180 Loss 6.4911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38% 212/559 [00:29<00:48,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 211 Batch 210 Loss 6.5135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43% 242/559 [00:33<00:44,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 241 Batch 240 Loss 6.4125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% 272/559 [00:37<00:40,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 271 Batch 270 Loss 6.3872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54% 302/559 [00:42<00:35,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 301 Batch 300 Loss 6.5874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59% 332/559 [00:46<00:31,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 331 Batch 330 Loss 7.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65% 362/559 [00:50<00:27,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 361 Batch 360 Loss 6.6516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 392/559 [00:54<00:23,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 391 Batch 390 Loss 6.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75% 422/559 [00:58<00:19,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 421 Batch 420 Loss 6.5490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81% 452/559 [01:03<00:14,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 451 Batch 450 Loss 6.9156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86% 482/559 [01:07<00:10,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 481 Batch 480 Loss 6.3051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92% 512/559 [01:11<00:06,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 511 Batch 510 Loss 6.6012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97% 542/559 [01:15<00:02,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 541 Batch 540 Loss 6.9131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 559/559 [01:18<00:00,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate loss:  tensor(5.2688, device='cuda:0')\n",
      "q-acc:  0.5036097623687738\n",
      "r-acc:  0.49741247131061045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch_id, batch in enumerate(loop):\n",
    "        # reset\n",
    "        optim.zero_grad()\n",
    "\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        q_start = batch['q_start'].to(device)\n",
    "        r_start = batch['r_start'].to(device)\n",
    "        q_end = batch['q_end'].to(device)\n",
    "        r_end = batch['r_end'].to(device)\n",
    "\n",
    "\n",
    "        # model output\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        \n",
    "        # q_start_logits, r_start_logits, q_end_logits, r_end_logits = torch.split(outputs, 1, 1)\n",
    "        q_start_logits, r_start_logits, q_end_logits, r_end_logits = torch.split(outputs, 1, 2)\n",
    "        \n",
    "        \n",
    "\n",
    "        q_start_logits = q_start_logits.squeeze(-1).contiguous()\n",
    "        r_start_logits = r_start_logits.squeeze(-1).contiguous()\n",
    "        q_end_logits = q_end_logits.squeeze(-1).contiguous()\n",
    "        r_end_logits = r_end_logits.squeeze(-1).contiguous()\n",
    "\n",
    "        q_start_loss = loss_fct(q_start_logits, q_start)\n",
    "        r_start_loss = loss_fct(r_start_logits, r_start)\n",
    "        q_end_loss = loss_fct(q_end_logits, q_end)\n",
    "        r_end_loss = loss_fct(r_end_logits, r_end)\n",
    "\n",
    "\n",
    "\n",
    "        loss = q_start_loss + r_start_loss + q_end_loss + r_end_loss\n",
    "\n",
    "        # calculate loss\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if batch_id % 50 == 0 and batch_id != 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "                batch_id + 1, batch_id, running_loss / 50))\n",
    "            running_loss = 0.0\n",
    "\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    evaluate(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "438b6a3e-eb6b-4d92-8c4e-b285458fe6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'aicup_model_bert_base_bilstm'\n",
    "torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88645025-2c50-450d-bb3b-4cfa15e97ef2",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab84e6-b8a5-4731-8091-801ccc3acefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'aicup_model_bert_base_bilstm'\n",
    "# model.load_state_dict(torch.load(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "debe6206-a536-4bcf-a67e-cf6a31bfd07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6199</td>\n",
       "      <td>\"-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- ...</td>\n",
       "      <td>\"If so , why do we still have apes , and why a...</td>\n",
       "      <td>DISAGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5807</td>\n",
       "      <td>\"There 's a lot of discussion there on that is...</td>\n",
       "      <td>\"Of course . The makers of Expelled were withi...</td>\n",
       "      <td>DISAGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8487</td>\n",
       "      <td>\"`` It 's not helping . The guns these people ...</td>\n",
       "      <td>\"Oh , I would wager about like Mexico , about ...</td>\n",
       "      <td>DISAGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1760</td>\n",
       "      <td>\"Shooting : 3 seriously injured in Auburn shoo...</td>\n",
       "      <td>\"Pickup strikes group of four youths | Houston...</td>\n",
       "      <td>AGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6228</td>\n",
       "      <td>\"This is the argument concerning 'choice ' tha...</td>\n",
       "      <td>\"I believe there is a point at which we ( soci...</td>\n",
       "      <td>DISAGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>9499</td>\n",
       "      <td>\"You are betraying your belief system .\"</td>\n",
       "      <td>\"Yep . ( I 'm assuming that by `` belief syste...</td>\n",
       "      <td>AGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>4611</td>\n",
       "      <td>\"You are in a loud minority , railing against ...</td>\n",
       "      <td>\"Being in the minority or in the majority is i...</td>\n",
       "      <td>DISAGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>9328</td>\n",
       "      <td>\"You bet your XXX that 'd make me happy .\"</td>\n",
       "      <td>\"Well , first , I probably would n't bet my XX...</td>\n",
       "      <td>DISAGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>5225</td>\n",
       "      <td>\"you say `` f * * * the Constitution. ``\"</td>\n",
       "      <td>\"and gun nuts say f * * * the children when we...</td>\n",
       "      <td>DISAGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>68</td>\n",
       "      <td>\"Your answers were without content or meaning ...</td>\n",
       "      <td>\"k\"</td>\n",
       "      <td>DISAGREE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2016 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                                  q  \\\n",
       "0     6199  \"-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- ...   \n",
       "1     5807  \"There 's a lot of discussion there on that is...   \n",
       "2     8487  \"`` It 's not helping . The guns these people ...   \n",
       "3     1760  \"Shooting : 3 seriously injured in Auburn shoo...   \n",
       "4     6228  \"This is the argument concerning 'choice ' tha...   \n",
       "...    ...                                                ...   \n",
       "2011  9499           \"You are betraying your belief system .\"   \n",
       "2012  4611  \"You are in a loud minority , railing against ...   \n",
       "2013  9328         \"You bet your XXX that 'd make me happy .\"   \n",
       "2014  5225          \"you say `` f * * * the Constitution. ``\"   \n",
       "2015    68  \"Your answers were without content or meaning ...   \n",
       "\n",
       "                                                      r         s  \n",
       "0     \"If so , why do we still have apes , and why a...  DISAGREE  \n",
       "1     \"Of course . The makers of Expelled were withi...  DISAGREE  \n",
       "2     \"Oh , I would wager about like Mexico , about ...  DISAGREE  \n",
       "3     \"Pickup strikes group of four youths | Houston...     AGREE  \n",
       "4     \"I believe there is a point at which we ( soci...  DISAGREE  \n",
       "...                                                 ...       ...  \n",
       "2011  \"Yep . ( I 'm assuming that by `` belief syste...     AGREE  \n",
       "2012  \"Being in the minority or in the majority is i...  DISAGREE  \n",
       "2013  \"Well , first , I probably would n't bet my XX...  DISAGREE  \n",
       "2014  \"and gun nuts say f * * * the children when we...  DISAGREE  \n",
       "2015                                                \"k\"  DISAGREE  \n",
       "\n",
       "[2016 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('Batch_answers - test_data(no_label).csv', encoding=\"ISO-8859-1\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c03315d-4d49-45ae-bc12-addd87f8cda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6199</td>\n",
       "      <td>-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -...</td>\n",
       "      <td>DISAGREE:If so , why do we still have apes , a...</td>\n",
       "      <td>DISAGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5807</td>\n",
       "      <td>There 's a lot of discussion there on that iss...</td>\n",
       "      <td>DISAGREE:Of course . The makers of Expelled we...</td>\n",
       "      <td>DISAGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8487</td>\n",
       "      <td>`` It 's not helping . The guns these people h...</td>\n",
       "      <td>DISAGREE:Oh , I would wager about like Mexico ...</td>\n",
       "      <td>DISAGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1760</td>\n",
       "      <td>Shooting : 3 seriously injured in Auburn shoot...</td>\n",
       "      <td>AGREE:Pickup strikes group of four youths | Ho...</td>\n",
       "      <td>AGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6228</td>\n",
       "      <td>This is the argument concerning 'choice ' that...</td>\n",
       "      <td>DISAGREE:I believe there is a point at which w...</td>\n",
       "      <td>DISAGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>9499</td>\n",
       "      <td>You are betraying your belief system .</td>\n",
       "      <td>AGREE:Yep . ( I 'm assuming that by `` belief ...</td>\n",
       "      <td>AGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>4611</td>\n",
       "      <td>You are in a loud minority , railing against t...</td>\n",
       "      <td>DISAGREE:Being in the minority or in the major...</td>\n",
       "      <td>DISAGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>9328</td>\n",
       "      <td>You bet your XXX that 'd make me happy .</td>\n",
       "      <td>DISAGREE:Well , first , I probably would n't b...</td>\n",
       "      <td>DISAGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>5225</td>\n",
       "      <td>you say `` f * * * the Constitution. ``</td>\n",
       "      <td>DISAGREE:and gun nuts say f * * * the children...</td>\n",
       "      <td>DISAGREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>68</td>\n",
       "      <td>Your answers were without content or meaning ....</td>\n",
       "      <td>DISAGREE:k</td>\n",
       "      <td>DISAGREE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2016 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                                  q  \\\n",
       "0     6199  -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -...   \n",
       "1     5807  There 's a lot of discussion there on that iss...   \n",
       "2     8487  `` It 's not helping . The guns these people h...   \n",
       "3     1760  Shooting : 3 seriously injured in Auburn shoot...   \n",
       "4     6228  This is the argument concerning 'choice ' that...   \n",
       "...    ...                                                ...   \n",
       "2011  9499             You are betraying your belief system .   \n",
       "2012  4611  You are in a loud minority , railing against t...   \n",
       "2013  9328           You bet your XXX that 'd make me happy .   \n",
       "2014  5225            you say `` f * * * the Constitution. ``   \n",
       "2015    68  Your answers were without content or meaning ....   \n",
       "\n",
       "                                                      r         s  \n",
       "0     DISAGREE:If so , why do we still have apes , a...  DISAGREE  \n",
       "1     DISAGREE:Of course . The makers of Expelled we...  DISAGREE  \n",
       "2     DISAGREE:Oh , I would wager about like Mexico ...  DISAGREE  \n",
       "3     AGREE:Pickup strikes group of four youths | Ho...     AGREE  \n",
       "4     DISAGREE:I believe there is a point at which w...  DISAGREE  \n",
       "...                                                 ...       ...  \n",
       "2011  AGREE:Yep . ( I 'm assuming that by `` belief ...     AGREE  \n",
       "2012  DISAGREE:Being in the minority or in the major...  DISAGREE  \n",
       "2013  DISAGREE:Well , first , I probably would n't b...  DISAGREE  \n",
       "2014  DISAGREE:and gun nuts say f * * * the children...  DISAGREE  \n",
       "2015                                         DISAGREE:k  DISAGREE  \n",
       "\n",
       "[2016 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['q', 'r']] = df_test[['q', 'r']].apply(lambda x: x.str.strip('\\\"'))\n",
    "df_test['r'] = df_test['s'] + ':' + df_test['r']\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85d9346-f4a4-49cb-9f72-7290a9ce8fb8",
   "metadata": {},
   "source": [
    "---\n",
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436bd512-bd1a-4e73-9dd1-dcb8c07f36ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_q = df_test['q'].tolist()\n",
    "test_data_r = df_test['r'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d8bbac-5993-4db9-a418-0a7e006bc9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encodings = tokenizer(test_data_q, test_data_r, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba7e2f4-376a-4fd9-96b9-82b74e84e5e7",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d231834c-15ec-4b54-b269-54e38ba7d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = qrDataset(test_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b95bef-335c-42b7-badd-6f191f43a2a0",
   "metadata": {},
   "source": [
    "---\n",
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e65be2ed-1503-43c0-876c-12780ba45a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a7d76-09ab-4c22-b4b8-eb9878735ca3",
   "metadata": {},
   "source": [
    "---\n",
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b291bf0-8fe3-4819-889b-c49f49bab37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def predict(test_loader):\n",
    "    predict_pos = []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    q_sub_output, r_sub_output = [],[]\n",
    "\n",
    "    loop = tqdm(test_loader, leave=True)\n",
    "    for batch_id, batch in enumerate(loop):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "\n",
    "        # model output\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        \n",
    "        q_start_logits, r_start_logits, q_end_logits, r_end_logits = torch.split(outputs, 1, 2)\n",
    "\n",
    "        q_start_logits = q_start_logits.squeeze(-1).contiguous()\n",
    "        r_start_logits = r_start_logits.squeeze(-1).contiguous()\n",
    "        q_end_logits = q_end_logits.squeeze(-1).contiguous()\n",
    "        r_end_logits = r_end_logits.squeeze(-1).contiguous()\n",
    "\n",
    "        q_start_prdict = torch.argmax(q_start_logits, 1).cpu().numpy()\n",
    "        r_start_prdict = torch.argmax(r_start_logits, 1).cpu().numpy()\n",
    "        q_end_prdict = torch.argmax(q_end_logits, 1).cpu().numpy()\n",
    "        r_end_prdict = torch.argmax(r_end_logits, 1).cpu().numpy()\n",
    "\n",
    "        for i in range(len(input_ids)):\n",
    "            predict_pos.append((q_start_prdict[i].item(), r_start_prdict[i].item(), q_end_prdict[i].item(), r_end_prdict[i].item()))\n",
    "\n",
    "            q_sub = tokenizer.decode(input_ids[i][q_start_prdict[i]:q_end_prdict[i]+1])\n",
    "            r_sub = tokenizer.decode(input_ids[i][r_start_prdict[i]:r_end_prdict[i]+1])\n",
    "            \n",
    "            q_sub_output.append(q_sub)\n",
    "            r_sub_output.append(r_sub)\n",
    "    \n",
    "    return q_sub_output, r_sub_output, predict_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed9c0401-3308-4968-9d6c-e255c1429f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 252/252 [00:34<00:00,  7.28it/s]\n"
     ]
    }
   ],
   "source": [
    "q_sub_output, r_sub_output, predict_pos = predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0691f1b3-b5da-41e1-9707-aaf2f43f946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_post_fn(test, q_sub_output, r_sub_output):\n",
    "    q_sub, r_sub = [], []\n",
    "    for i in range(len(test)):\n",
    "\n",
    "        q_sub_pred = q_sub_output[i].split()\n",
    "        r_sub_pred = r_sub_output[i].split()\n",
    "\n",
    "        if q_sub_pred is None:\n",
    "            q_sub_pred = []\n",
    "        q_sub_error_index = q_sub_pred.index('[SEP]') if '[SEP]' in q_sub_pred else -1\n",
    "\n",
    "        if q_sub_error_index != -1:\n",
    "            q_sub_pred = q_sub_pred[:q_sub_error_index]\n",
    "\n",
    "        temp = r_sub_pred.copy()\n",
    "        if r_sub_pred is None:\n",
    "            r_sub_pred = []\n",
    "        else:\n",
    "            for j in range(len(temp)):\n",
    "                if temp[j] == '[SEP]':\n",
    "                    r_sub_pred.remove('[SEP]')\n",
    "                if temp[j] == '[PAD]':\n",
    "                    r_sub_pred.remove('[PAD]')\n",
    "\n",
    "        q_sub.append(' '.join(q_sub_pred))\n",
    "        r_sub.append(' '.join(r_sub_pred))\n",
    "\n",
    "    return q_sub, r_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b458011-502b-455d-be7f-feda181f5b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_sub, r_sub = get_output_post_fn(df_test, q_sub_output, r_sub_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be253de4-00d2-4dbf-8a3a-497072cd46e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>q_sub</th>\n",
       "      <th>r_sub</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6199</th>\n",
       "      <td>-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -...</td>\n",
       "      <td>DISAGREE:If so , why do we still have apes , a...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>- - - - - - - - - - - - - - - - - - - - - - - ...</td>\n",
       "      <td>If so, why do we still have apes, and why are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5807</th>\n",
       "      <td>There 's a lot of discussion there on that iss...</td>\n",
       "      <td>DISAGREE:Of course . The makers of Expelled we...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>There's a lot of discussion there on that issu...</td>\n",
       "      <td>The makers of Expelled were within their right...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8487</th>\n",
       "      <td>`` It 's not helping . The guns these people h...</td>\n",
       "      <td>DISAGREE:Oh , I would wager about like Mexico ...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>It's not helping. The guns these people have, ...</td>\n",
       "      <td>Oh, I would wager about like Mexico, about 80 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>Shooting : 3 seriously injured in Auburn shoot...</td>\n",
       "      <td>AGREE:Pickup strikes group of four youths | Ho...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>Shooting : 3 seriously injured in Auburn shoot...</td>\n",
       "      <td>This is America! You don't need no stinkin'mot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6228</th>\n",
       "      <td>This is the argument concerning 'choice ' that...</td>\n",
       "      <td>DISAGREE:I believe there is a point at which w...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>This is the argument concerning'choice'that, t...</td>\n",
       "      <td>I believe there is a point at which we ( socie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9499</th>\n",
       "      <td>You are betraying your belief system .</td>\n",
       "      <td>AGREE:Yep . ( I 'm assuming that by `` belief ...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>You are betraying your belief system.</td>\n",
       "      <td>Yep. ( I'm assuming that by ` ` belief system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>You are in a loud minority , railing against t...</td>\n",
       "      <td>DISAGREE:Being in the minority or in the major...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>You are in a loud minority, railing against th...</td>\n",
       "      <td>Being in the minority or in the majority is ir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9328</th>\n",
       "      <td>You bet your XXX that 'd make me happy .</td>\n",
       "      <td>DISAGREE:Well , first , I probably would n't b...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>You bet your XXX that'd make me happy.</td>\n",
       "      <td>I probably wouldn't bet my XXX, but whatever y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5225</th>\n",
       "      <td>you say `` f * * * the Constitution. ``</td>\n",
       "      <td>DISAGREE:and gun nuts say f * * * the children...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>you say ` ` f * * * the Constitution. ` `</td>\n",
       "      <td>and gun nuts say f * * * the children when we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Your answers were without content or meaning ....</td>\n",
       "      <td>DISAGREE:k</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>Your answers were without content or meaning. ...</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2016 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      q  \\\n",
       "id                                                        \n",
       "6199  -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -...   \n",
       "5807  There 's a lot of discussion there on that iss...   \n",
       "8487  `` It 's not helping . The guns these people h...   \n",
       "1760  Shooting : 3 seriously injured in Auburn shoot...   \n",
       "6228  This is the argument concerning 'choice ' that...   \n",
       "...                                                 ...   \n",
       "9499             You are betraying your belief system .   \n",
       "4611  You are in a loud minority , railing against t...   \n",
       "9328           You bet your XXX that 'd make me happy .   \n",
       "5225            you say `` f * * * the Constitution. ``   \n",
       "68    Your answers were without content or meaning ....   \n",
       "\n",
       "                                                      r         s  \\\n",
       "id                                                                  \n",
       "6199  DISAGREE:If so , why do we still have apes , a...  DISAGREE   \n",
       "5807  DISAGREE:Of course . The makers of Expelled we...  DISAGREE   \n",
       "8487  DISAGREE:Oh , I would wager about like Mexico ...  DISAGREE   \n",
       "1760  AGREE:Pickup strikes group of four youths | Ho...     AGREE   \n",
       "6228  DISAGREE:I believe there is a point at which w...  DISAGREE   \n",
       "...                                                 ...       ...   \n",
       "9499  AGREE:Yep . ( I 'm assuming that by `` belief ...     AGREE   \n",
       "4611  DISAGREE:Being in the minority or in the major...  DISAGREE   \n",
       "9328  DISAGREE:Well , first , I probably would n't b...  DISAGREE   \n",
       "5225  DISAGREE:and gun nuts say f * * * the children...  DISAGREE   \n",
       "68                                           DISAGREE:k  DISAGREE   \n",
       "\n",
       "                                                  q_sub  \\\n",
       "id                                                        \n",
       "6199  - - - - - - - - - - - - - - - - - - - - - - - ...   \n",
       "5807  There's a lot of discussion there on that issu...   \n",
       "8487  It's not helping. The guns these people have, ...   \n",
       "1760  Shooting : 3 seriously injured in Auburn shoot...   \n",
       "6228  This is the argument concerning'choice'that, t...   \n",
       "...                                                 ...   \n",
       "9499              You are betraying your belief system.   \n",
       "4611  You are in a loud minority, railing against th...   \n",
       "9328             You bet your XXX that'd make me happy.   \n",
       "5225          you say ` ` f * * * the Constitution. ` `   \n",
       "68    Your answers were without content or meaning. ...   \n",
       "\n",
       "                                                  r_sub  \n",
       "id                                                       \n",
       "6199  If so, why do we still have apes, and why are ...  \n",
       "5807  The makers of Expelled were within their right...  \n",
       "8487  Oh, I would wager about like Mexico, about 80 ...  \n",
       "1760  This is America! You don't need no stinkin'mot...  \n",
       "6228  I believe there is a point at which we ( socie...  \n",
       "...                                                 ...  \n",
       "9499  Yep. ( I'm assuming that by ` ` belief system ...  \n",
       "4611  Being in the minority or in the majority is ir...  \n",
       "9328  I probably wouldn't bet my XXX, but whatever y...  \n",
       "5225  and gun nuts say f * * * the children when we ...  \n",
       "68                                                    k  \n",
       "\n",
       "[2016 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['q_sub'] = q_sub\n",
    "df_test['r_sub'] = r_sub\n",
    "df_test = df_test.set_index('id')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db5a465-46be-447c-b2aa-0e933b05ceeb",
   "metadata": {},
   "source": [
    "---\n",
    "# To CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdedf7fd-61e5-4dd0-96e9-056892a6e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.read_csv('submission template.csv')\n",
    "df_result = df_result.set_index('id')\n",
    "df_result = pd.merge(df_result, df_test[['q_sub', 'r_sub']], left_index=True, right_index=True)\n",
    "df_result = df_result.reset_index()\n",
    "df_result = df_result.drop(['q', 'r'], axis=1)\n",
    "df_result = df_result.rename(columns={\"q_sub\": \"q\", \"r_sub\": \"r\"})\n",
    "# df_result[[\"q\", \"r\"]] = df_result[[\"q\", \"r\"]].astype(str)\n",
    "df_result.update('\"' + df_result[['q', 'r']].astype(str) + '\"')\n",
    "\n",
    "df_result.to_csv('submission_bert_base_bilstm.csv', encoding=\"utf-8\", sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83966b1b-b680-4b7f-858c-6d276e22d233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"I got a good idea. however, they do tend to s...</td>\n",
       "      <td>\"By your own admission you [UNK] Ã¢ t'hung out'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Be sure to give your guns a big fat kiss toni...</td>\n",
       "      <td>\"Actually, they didn't. The whole tragedy was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"One of the biggest arguments against gun cont...</td>\n",
       "      <td>\"Not quite. To be more correct regarding gover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"First of all, compare the'B'specimen in your ...</td>\n",
       "      <td>\"Comparison I could've just circled the whole ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"There are some incedents that are beyond your...</td>\n",
       "      <td>\"Well yes.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"So the answer to your question is that there ...</td>\n",
       "      <td>\"So which is it : the action is moral, the act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Legality does not matter. Religous implicatio...</td>\n",
       "      <td>\"Exact, to the point, &amp; amp ; beautiful.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>\"Correctly viewed, evolution is not a series o...</td>\n",
       "      <td>\"\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>\"I was under the impression this article was r...</td>\n",
       "      <td>\"You're not one of those people who doesn't co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>\"And dont you get a kick out of SP calling her...</td>\n",
       "      <td>\"Actually he doesn't believe in a liar God lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18</td>\n",
       "      <td>\"It took me a few years to see through the fai...</td>\n",
       "      <td>\"um, yeah, you could say that\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19</td>\n",
       "      <td>\"i love these kinds of arguments! both sides a...</td>\n",
       "      <td>\"I'm not in denial about anything and don't th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>\"I strongly disagree with gay marriage anyway....</td>\n",
       "      <td>\"Because you say so?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21</td>\n",
       "      <td>\"That gives me an idea. Why don't we have a co...</td>\n",
       "      <td>\"Oh! mememe! I have an idea! The museum staff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>\"And I'd think the explanation would be that o...</td>\n",
       "      <td>\"And yet the species that exist today are the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>\"there are various fossilization mechanisms. I...</td>\n",
       "      <td>\"Well, Google is your friend here - try fossil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>\"Do you mean sexually molesting children? Agai...</td>\n",
       "      <td>\"What if a 13 year old girl comes up to you an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>\"And the king of Babylon smote them and put th...</td>\n",
       "      <td>\"You didn't bother to read the link, I see, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>\"Coal can form quickly when forests and marine...</td>\n",
       "      <td>\"Reference please.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27</td>\n",
       "      <td>\"Where is the evidence for an American - style...</td>\n",
       "      <td>\"So are you saying that the people of India ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>28</td>\n",
       "      <td>\"Viva La Liberty!\"</td>\n",
       "      <td>\"I see you Americans deal as loosely with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>43</td>\n",
       "      <td>\"If abortion were illegal, anyone caught perfo...</td>\n",
       "      <td>\"From that site :\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>44</td>\n",
       "      <td>\"Senior citizen yachties stand little chance o...</td>\n",
       "      <td>\"And you think the British would do that?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>45</td>\n",
       "      <td>\"[UNK] Ã¢ m against gay marriage and have been ...</td>\n",
       "      <td>\"Ahah! The exception that proves the rule!\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>46</td>\n",
       "      <td>\"With a shotgun and his dog, he tried to defen...</td>\n",
       "      <td>\"What can ya expect when they killed free spee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>47</td>\n",
       "      <td>\"And the only reason the criminals hold handgu...</td>\n",
       "      <td>\"I presume that is a joke. Criminals have alwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>48</td>\n",
       "      <td>\"Show me even one instance of the National med...</td>\n",
       "      <td>\"I'm not sure what you mean by the other side ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>49</td>\n",
       "      <td>\"the type of atheism you are talking about her...</td>\n",
       "      <td>\"Maybe you'll have to clear up the difference ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50</td>\n",
       "      <td>\"Are you sure about that? Do you know who mai'...</td>\n",
       "      <td>\"You're right, I think he has made such commen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>51</td>\n",
       "      <td>\"The IRA comes to mind. Or wasn't I supposed t...</td>\n",
       "      <td>\"Just so you don't shoot them!\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                                  q  \\\n",
       "0    1  \"I got a good idea. however, they do tend to s...   \n",
       "1    2  \"Be sure to give your guns a big fat kiss toni...   \n",
       "2    3  \"One of the biggest arguments against gun cont...   \n",
       "3    4  \"First of all, compare the'B'specimen in your ...   \n",
       "4    5  \"There are some incedents that are beyond your...   \n",
       "5    6  \"So the answer to your question is that there ...   \n",
       "6    7  \"Legality does not matter. Religous implicatio...   \n",
       "7   15  \"Correctly viewed, evolution is not a series o...   \n",
       "8   16  \"I was under the impression this article was r...   \n",
       "9   17  \"And dont you get a kick out of SP calling her...   \n",
       "10  18  \"It took me a few years to see through the fai...   \n",
       "11  19  \"i love these kinds of arguments! both sides a...   \n",
       "12  20  \"I strongly disagree with gay marriage anyway....   \n",
       "13  21  \"That gives me an idea. Why don't we have a co...   \n",
       "14  22  \"And I'd think the explanation would be that o...   \n",
       "15  23  \"there are various fossilization mechanisms. I...   \n",
       "16  24  \"Do you mean sexually molesting children? Agai...   \n",
       "17  25  \"And the king of Babylon smote them and put th...   \n",
       "18  26  \"Coal can form quickly when forests and marine...   \n",
       "19  27  \"Where is the evidence for an American - style...   \n",
       "20  28                                 \"Viva La Liberty!\"   \n",
       "21  43  \"If abortion were illegal, anyone caught perfo...   \n",
       "22  44  \"Senior citizen yachties stand little chance o...   \n",
       "23  45  \"[UNK] Ã¢ m against gay marriage and have been ...   \n",
       "24  46  \"With a shotgun and his dog, he tried to defen...   \n",
       "25  47  \"And the only reason the criminals hold handgu...   \n",
       "26  48  \"Show me even one instance of the National med...   \n",
       "27  49  \"the type of atheism you are talking about her...   \n",
       "28  50  \"Are you sure about that? Do you know who mai'...   \n",
       "29  51  \"The IRA comes to mind. Or wasn't I supposed t...   \n",
       "\n",
       "                                                    r  \n",
       "0   \"By your own admission you [UNK] Ã¢ t'hung out'...  \n",
       "1   \"Actually, they didn't. The whole tragedy was ...  \n",
       "2   \"Not quite. To be more correct regarding gover...  \n",
       "3   \"Comparison I could've just circled the whole ...  \n",
       "4                                         \"Well yes.\"  \n",
       "5   \"So which is it : the action is moral, the act...  \n",
       "6           \"Exact, to the point, & amp ; beautiful.\"  \n",
       "7                                                  \"\"  \n",
       "8   \"You're not one of those people who doesn't co...  \n",
       "9   \"Actually he doesn't believe in a liar God lik...  \n",
       "10                     \"um, yeah, you could say that\"  \n",
       "11  \"I'm not in denial about anything and don't th...  \n",
       "12                              \"Because you say so?\"  \n",
       "13  \"Oh! mememe! I have an idea! The museum staff ...  \n",
       "14  \"And yet the species that exist today are the ...  \n",
       "15  \"Well, Google is your friend here - try fossil...  \n",
       "16  \"What if a 13 year old girl comes up to you an...  \n",
       "17  \"You didn't bother to read the link, I see, wh...  \n",
       "18                                \"Reference please.\"  \n",
       "19  \"So are you saying that the people of India ar...  \n",
       "20  \"I see you Americans deal as loosely with the ...  \n",
       "21                                 \"From that site :\"  \n",
       "22         \"And you think the British would do that?\"  \n",
       "23        \"Ahah! The exception that proves the rule!\"  \n",
       "24  \"What can ya expect when they killed free spee...  \n",
       "25  \"I presume that is a joke. Criminals have alwa...  \n",
       "26  \"I'm not sure what you mean by the other side ...  \n",
       "27  \"Maybe you'll have to clear up the difference ...  \n",
       "28  \"You're right, I think he has made such commen...  \n",
       "29                    \"Just so you don't shoot them!\"  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[:30]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
